{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Noppawat-Tantisiriwat/Thai-Music-Generation/blob/main/AIB_Master_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fxEWI_WFncQ"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0ASh9TLpFvwG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LayerNormalization, \\\n",
    "    Flatten, Dense, Reshape, Conv1DTranspose, Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import datetime, os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d-VmvLF8FnPO"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXWh3xT3GTvb",
    "outputId": "b4f1d7b5-5e1b-40ee-f301-4cfd6d95a13b"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp8nuEHGZp4L"
   },
   "source": [
    "## Connect to your working directory path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfYEJXU5GWNc",
    "outputId": "2e162361-913d-4494-8679-b49cb49fcd5a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khQrCXcNIwEq"
   },
   "outputs": [],
   "source": [
    "# if not have folder yet\n",
    "# %mkdir /content/drive/MyDrive/AIB_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u5BVgUrGWu2",
    "outputId": "6d1c7086-a7db-4b00-d41f-e856d71672d3"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/AIB_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_sch5qqdcFg",
    "outputId": "099e2298-dff4-4de5-d99f-d113e946e9f2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd Your_working_directory_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_Onm4L0FGnl"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PIkvHTC083lr"
   },
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "  def __init__(self, \n",
    "               inp_shape: List[int],\n",
    "               conv_filters: List[int],\n",
    "               conv_kernels: List[int],\n",
    "               conv_strides: List[int],\n",
    "               latent_space_dim: int, \n",
    "               **kwargs):\n",
    "    super(Encoder, self).__init__(**kwargs)\n",
    "    self.conv_filters = conv_filters # [2, 4, 8]\n",
    "    self.conv_kernels = conv_kernels # [3, 5, 3]\n",
    "    self.conv_strides = conv_strides # [1, 2, 2]\n",
    "    self.latent_space_dim = latent_space_dim # 2\n",
    "    self._shape_before_bottleneck = None\n",
    "    # dim assertion\n",
    "    assert len(self.conv_strides) == len(self.conv_kernels) == len(self.conv_filters)\n",
    "\n",
    "    self.convs = [Conv1D(\n",
    "        filters=f,\n",
    "        kernel_size=k,\n",
    "        strides=s,\n",
    "        padding=\"same\",\n",
    "        name=f\"encoder_conv_layer_{i}\",\n",
    "        activation=\"relu\"\n",
    "    ) for i, (f, k, s) in enumerate(zip(self.conv_filters, self.conv_kernels, self.conv_strides))]\n",
    "\n",
    "    self.layernorms = [LayerNormalization(name=f\"encoder_ln_{i}\") for i in range(len(self.conv_filters))]\n",
    "    \n",
    "    self.flatten = Flatten()\n",
    "    # dim assertion\n",
    "    assert len(self.convs) == len(self.layernorms)\n",
    "\n",
    "    self.dense_mu = Dense(self.latent_space_dim, name=\"mu\")\n",
    "\n",
    "    self.dense_logvar = Dense(self.latent_space_dim, name=\"log_variance\")\n",
    "\n",
    "    self._compute_shape_before_bottleneck(inp_shape)\n",
    "\n",
    "\n",
    "  def _compute_shape_before_bottleneck(self, inp_shape: List[int]):\n",
    "    x = tf.zeros(shape=inp_shape) # dummy data\n",
    "    x= tf.expand_dims(x, axis=0) # batching\n",
    "    for conv, layernorm in zip(self.convs, self.layernorms):\n",
    "      x = conv(x)\n",
    "      x = layernorm(x)\n",
    "    self._shape_before_bottleneck = tf.shape(x)[1:] # (None, shape) -> (shape) [None = batch_size]\n",
    "  \n",
    "  def _reparameterized(self, mu, log_var):\n",
    "    eps = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
    "    sample_point = mu + K.exp(log_var / 2) * eps\n",
    "    return sample_point\n",
    "\n",
    "  def call(self, x):\n",
    "    for conv, layernorm in zip(self.convs, self.layernorms):\n",
    "      x = conv(x)\n",
    "      x = layernorm(x)\n",
    "    x = self.flatten(x)\n",
    "    mu = self.dense_mu(x)\n",
    "    log_var = self.dense_logvar(x)\n",
    "    x = self._reparameterized(mu, log_var)\n",
    "    return x, (mu, log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Dcp1P4eXFF8w"
   },
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "  def __init__(self,\n",
    "               shape_before_bottleneck: tf.Tensor,\n",
    "               conv_filters: List[int], # the first element must be 1\n",
    "               conv_kernels: List[int],\n",
    "               conv_strides: List[int],\n",
    "               out_channel: int,\n",
    "               **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.conv_filters = conv_filters\n",
    "    self.conv_kernels = conv_kernels\n",
    "    self.conv_strides = conv_strides\n",
    "    self.dense = Dense(tf.reduce_prod(shape_before_bottleneck), name=\"decoder_dense\")\n",
    "    self.reshape = Reshape(shape_before_bottleneck.numpy())\n",
    "    self.out_channel = out_channel\n",
    "\n",
    "    # dim assertion\n",
    "    assert len(self.conv_strides) == len(self.conv_kernels) == len(self.conv_filters)\n",
    "\n",
    "    self.convs = [Conv1DTranspose(\n",
    "          filters=f,\n",
    "            kernel_size=k,\n",
    "            strides=s,\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{i}\",\n",
    "            activation=\"relu\"\n",
    "          ) for i, (f, k, s) in enumerate(zip(self.conv_filters[1:], self.conv_kernels[1:], self.conv_strides[1:]))]\n",
    "    self.layernorms = [LayerNormalization(name=f\"decoder_ln_{i}\") for i in range(len(self.conv_filters[1:]))]\n",
    "\n",
    "    # dim assertion\n",
    "    assert len(self.convs) == len(self.layernorms)\n",
    "\n",
    "    self.output_conv = Conv1DTranspose(\n",
    "        filters=self.out_channel,\n",
    "        kernel_size=self.conv_kernels[0],\n",
    "        strides=self.conv_strides[0],\n",
    "        padding=\"same\",\n",
    "        name=f\"decoder_conv_transpose_layer_{len(self.conv_strides)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.dense(x)\n",
    "    x = self.reshape(x)\n",
    "    for conv, layernorm in zip(self.convs, self.layernorms):\n",
    "            x = conv(x)\n",
    "            x = layernorm(x)\n",
    "    x = self.output_conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "7y5YW1WdFQHR"
   },
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "  def __init__(self,\n",
    "               inp_shape: List[int],\n",
    "               conv_filters: List[int],\n",
    "               conv_kernels: List[int],\n",
    "               conv_strides: List[int],\n",
    "               latent_space_dim: int,\n",
    "               recon_loss_weight: int,\n",
    "               **kwargs):\n",
    "    super(VAE, self).__init__(**kwargs)\n",
    "    self.inp_shape = inp_shape\n",
    "    self.recon_loss_weight = recon_loss_weight \n",
    "    self._shape_before_bottleneck = None\n",
    "    self.latent_space_dim = latent_space_dim\n",
    "    self._reduce_axis = list(range(1, len(inp_shape)+1))\n",
    "\n",
    "    self.encoder = Encoder(\n",
    "        inp_shape=inp_shape,\n",
    "        conv_filters=conv_filters,\n",
    "        conv_kernels=conv_kernels,\n",
    "        conv_strides=conv_strides,\n",
    "        latent_space_dim=latent_space_dim\n",
    "    )\n",
    "    \n",
    "    self.decoder = Decoder(\n",
    "        shape_before_bottleneck=self.encoder._shape_before_bottleneck,\n",
    "        conv_filters = conv_filters[::-1],\n",
    "        conv_kernels = conv_kernels[::-1],\n",
    "        conv_strides=conv_strides[::-1],\n",
    "        out_channel=inp_shape[-1]\n",
    "    )\n",
    "\n",
    "  def set_recon_loss_weight(self, recon_loss_weight):\n",
    "    self.recon_loss_weight = recon_loss_weight\n",
    "\n",
    "  def _calculate_kl_loss(self, mu, log_var):\n",
    "    kl_loss = -0.5 * tf.reduce_sum(1 + log_var -tf.square(mu) - tf.exp(log_var), axis=1)\n",
    "    return kl_loss\n",
    "\n",
    "  def _calculate_recon_loss(self, x, x_prime):\n",
    "    recon_loss = tf.reduce_mean(tf.square(x - x_prime), axis=self._reduce_axis)\n",
    "    return self.recon_loss_weight * recon_loss\n",
    "  \n",
    "  def _compute_loss(self, x, x_prime, mu, log_var):\n",
    "    recon_loss =  self._calculate_recon_loss(x, x_prime)\n",
    "    kl_loss =  self._calculate_kl_loss(mu, log_var)\n",
    "    loss =  recon_loss  + kl_loss\n",
    "    self.add_loss(tf.add_n([loss]))\n",
    "    self.add_metric(tf.add_n([recon_loss / self.recon_loss_weight]), name=\"recon_loss\")\n",
    "    self.add_metric(tf.add_n([kl_loss]), name=\"kl_loss\")\n",
    "\n",
    "  def call(self, x):\n",
    "    z, (mu, log_var) = self.encoder(x)\n",
    "    x_prime = self.decoder(z)\n",
    "    self._compute_loss(x, x_prime, mu, log_var)\n",
    "    return z, x_prime\n",
    "\n",
    "  def full_summary(self):\n",
    "    self.encoder.summary()\n",
    "    self.decoder.summary()\n",
    "    self.summary()\n",
    "\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal([1, self.latent_space_dim])\n",
    "      return self.decoder(eps)\n",
    "    else:\n",
    "      print(f\"sample epsilon: {eps}\")\n",
    "      return self.decoder(eps)\n",
    "\n",
    "  def reconstruct(self, images):\n",
    "    latent_representations = self.encoder.predict(images)\n",
    "    reconstructed_images = self.decoder.predict(latent_representations)\n",
    "    return reconstructed_images, latent_representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00E6lTB9HMmr"
   },
   "source": [
    "# Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "03SHwcnwH2aF"
   },
   "outputs": [],
   "source": [
    "def parse_function(example_proto):\n",
    "    features = {\n",
    "        'frequency': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'time': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'spectrograms': tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True)\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, features)\n",
    "\n",
    "    spectrogram = tf.reshape(parsed_features[\"spectrograms\"],\n",
    "                        [parsed_features[\"frequency\"], parsed_features['time']])\n",
    "\n",
    "    spectrogram = tf.transpose(spectrogram)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zX3aj4ZhITg7"
   },
   "outputs": [],
   "source": [
    "def get_train_data(tfrec_path):\n",
    "    train_data = tf.data.TFRecordDataset(tfrec_path)\\\n",
    "        .shuffle(300)\\\n",
    "        .map(parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "        .batch(32)\\\n",
    "        .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zI_wZTGBIFbR"
   },
   "outputs": [],
   "source": [
    "tfrec_path = r\"where-you-save-tfrec\"\n",
    "x_train = get_train_data(tfrec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hNLk50wtMNQb"
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "KQEsAMCsKHt5"
   },
   "outputs": [],
   "source": [
    "vae = VAE(inp_shape=[1296, 256], \n",
    "          conv_filters=[256, 512, 512, 1024],\n",
    "          conv_kernels=[5, 5, 5, 5],\n",
    "          conv_strides=[3, 3, 3, 3],\n",
    "          latent_space_dim=1024,\n",
    "          recon_loss_weight=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Ea1KEywlKSJi"
   },
   "outputs": [],
   "source": [
    "_ = vae(Input(shape=[1296, 256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "4GIU8AOwxRht"
   },
   "outputs": [],
   "source": [
    "vae.compile(Adam(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1LdcI0hGilJ",
    "outputId": "b7cc2d3d-4eed-4953-a135-768227d98e4d"
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"tensorboaed_logs/VAE_layernorms_new_arch\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "print(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R6APORwyJs3n"
   },
   "outputs": [],
   "source": [
    "checkpoint_file_path = \"T:\\\\AI_project\\\\Compress_and_model\\\\v.final\\\\model\\\\checkpoint_VAE_256_512_512_1024_rc1000000_layernorm\\\\weight_improvement_{epoch:02d}-{loss:.4f}\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_file_path,\n",
    "    monitor=\"loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyILZPE0fjUP"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing weight of L2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.set_recon_loss_weight(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.recon_loss_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100 # up to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OO2pGde4BsI3",
    "outputId": "8efd6268-a9dc-4867-960c-72962f805d7a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train, epochs=EPOCHS)\n",
    "# tf.keras.models.save_model(vae, \"T:\\\\DATASET\\\\v1.1\\\\model\\\\CNN1000\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy0sUXWhh5lC"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "d2emQvgeivY-",
    "outputId": "01d788e9-23dc-4bf8-8604-c4cfdb430412"
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(vae, \"where-you-want-to-save\", overwrite=True)\n",
    "#vae.save(filepath, save_format+\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WRX6-GySuNJ"
   },
   "source": [
    "# PRODUCE SOUND MAYBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fv_NWlruSZjP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pickle as p\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPV9q-DvUvLQ"
   },
   "outputs": [],
   "source": [
    "with open(\"E:\\\\datasethere\\\\MeanStdValue\\\\mean_std_values.pkl\", \"rb\") as file:\n",
    "  mean_std = p.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = mean_std[\"mean\"], mean_std[\"std\"]\n",
    "\n",
    "def denormalize(array, mean, std):\n",
    "    # denormalize\n",
    "    return array * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model):\n",
    "    eps = tf.random.normal([1, 1024])\n",
    "    log_spectrogram = model.decoder(eps)\n",
    "    log_spectrogram = tf.squeeze(log_spectrogram).numpy().T\n",
    "    log_denorm = denormalize(log_spectrogram, mean, std)\n",
    "    spectrogram = librosa.db_to_amplitude(log_denorm)\n",
    "    wave = librosa.griffinlim(spectrogram, hop_length=256, win_length=510)\n",
    "    return wave\n",
    "\n",
    "def main(num_generate, model_path, output):\n",
    "    os.makedirs(output)\n",
    "    vae = tf.keras.models.load_model(model_path)\n",
    "    for i in tqdm(range(num_generate)):\n",
    "        wave = generate(vae)\n",
    "        sf.write(os.path.join(output, f\"generation_no.{i+1:02d}.wav\"), wave, samplerate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "986f2VIUVvbx"
   },
   "outputs": [],
   "source": [
    "num_generate = 10 # up to you\n",
    "model_path = \"where-you-save-model\"\n",
    "output = \"where-you-want-your-files-to-be\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "244c519266c642949c5a6484d52e17f8",
      "40815aac65bc4cdba08a46d737b6e747",
      "d7235b218e8e44ae8cd0efb5d2e553c5",
      "ef199a3de1c34c588533f0eba527bc6e",
      "6b9bc670b10f4a4991a08b76ebac3b45",
      "17c94dcb1ad046d495ca933d7d315a48",
      "715119b13c9941b1858e1e208c23d31d",
      "9aa9605ba7ed4822a6aa75b14666cda7",
      "7874b4dc5b7e429192adae385f9bf409",
      "c9201f81478541f6be2af9a27d1ef4e7",
      "0e9103e6556e46a8af0f7755a63da271"
     ]
    },
    "id": "wKEpBc1lSJuh",
    "outputId": "96015e96-a778-47be-f94c-2e6446523c3e"
   },
   "outputs": [],
   "source": [
    "# start generating your audio files\n",
    "main(num_generate, model_path, output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "p_0BSCBeBh2c",
    "l6242cVZrNP-"
   ],
   "name": "AIB_Master_CNN.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e9103e6556e46a8af0f7755a63da271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17c94dcb1ad046d495ca933d7d315a48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "244c519266c642949c5a6484d52e17f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40815aac65bc4cdba08a46d737b6e747",
       "IPY_MODEL_d7235b218e8e44ae8cd0efb5d2e553c5",
       "IPY_MODEL_ef199a3de1c34c588533f0eba527bc6e"
      ],
      "layout": "IPY_MODEL_6b9bc670b10f4a4991a08b76ebac3b45"
     }
    },
    "40815aac65bc4cdba08a46d737b6e747": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17c94dcb1ad046d495ca933d7d315a48",
      "placeholder": "​",
      "style": "IPY_MODEL_715119b13c9941b1858e1e208c23d31d",
      "value": "100%"
     }
    },
    "6b9bc670b10f4a4991a08b76ebac3b45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "715119b13c9941b1858e1e208c23d31d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7874b4dc5b7e429192adae385f9bf409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9aa9605ba7ed4822a6aa75b14666cda7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9201f81478541f6be2af9a27d1ef4e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7235b218e8e44ae8cd0efb5d2e553c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9aa9605ba7ed4822a6aa75b14666cda7",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7874b4dc5b7e429192adae385f9bf409",
      "value": 10
     }
    },
    "ef199a3de1c34c588533f0eba527bc6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9201f81478541f6be2af9a27d1ef4e7",
      "placeholder": "​",
      "style": "IPY_MODEL_0e9103e6556e46a8af0f7755a63da271",
      "value": " 10/10 [00:26&lt;00:00,  1.79s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
